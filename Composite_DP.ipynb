{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHFzhB3a3x_w",
        "outputId": "5b462513-9d6e-42cc-f3b2-94a636ac0415"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCu-u7_frtw0"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-privacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uzhMTjncEL_"
      },
      "outputs": [],
      "source": [
        "import tensorflow_privacy\n",
        "\n",
        "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eNDqbyjL-wBM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow_privacy.privacy.dp_query.normalized_query import NormalizedQuery\n",
        "from tensorflow_privacy.privacy.dp_query.no_privacy_query import NoPrivacyAverageQuery\n",
        "from tensorflow_privacy.privacy.membership_inference_attack import membership_inference_attack as mia\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "batch_size = 32\n",
        "img_height = 75\n",
        "img_width = 75\n",
        "\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "tf.random.set_seed(123)\n",
        "\n",
        "# Define the paths to the data and the model checkpoints\n",
        "# data_dir = '/content/drive/MyDrive/MTP-2/chest_xray'\n",
        "model_dir = '/content/drive/MyDrive/MTP-2'\n",
        "\n",
        "# Define the privacy parameters\n",
        "# epsilon = 1.0\n",
        "# delta = 1e-6\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/MTP-2/chest_xray/train',\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/MTP-2/chest_xray/test',\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Extract the images and labels from the datasets\n",
        "train_images, train_labels = [], []\n",
        "test_images, test_labels = [], []\n",
        "for images, labels in train_ds:\n",
        "    train_images.append(images.numpy())\n",
        "    train_labels.append(labels.numpy())\n",
        "train_images = np.concatenate(train_images)\n",
        "train_labels = np.concatenate(train_labels)\n",
        "for images, labels in test_ds:\n",
        "    test_images.append(images.numpy())\n",
        "    test_labels.append(labels.numpy())\n",
        "test_images = np.concatenate(test_images)\n",
        "test_labels = np.concatenate(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1plkvDxOU-Fp"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.applications.densenet import DenseNet121\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "base_model = DenseNet121(include_top=False, weights=None, input_shape=(img_height, img_width, 3)) #32\n",
        "\n",
        "# base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(img_height, img_width, 3)) #32\n",
        "# base_model = keras.applications.InceptionV3(include_top=False, weights='imagenet', input_shape=(img_height, img_width, 3)) #75\n",
        "# base_model = keras.applications.VGG16(include_top=False, weights='imagenet', input_shape=(img_height, img_width, 3)) #75\n",
        "# weights_path = 'https://github.com/zoogzog/chexnet/raw/master/model.h5'\n",
        "# base_model.load_weights(weights_path)\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "# # x = Dropout(0.5)(x) # Regularization\n",
        "predictions = Dense(num_classes, activation='sigmoid')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "# model.layers.po\n",
        "\n",
        "epoch=2\n",
        "model.compile(optimizer=Adam(learning_rate=0.01),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "# Train the model without differential privacy\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=epoch)\n",
        "\n",
        "\n",
        "\n",
        "test_data = val_ds.take(1)\n",
        "test_images, test_labels = next(iter(test_data))\n",
        "output = model(test_images)\n",
        "predictions = tf.argmax(output, axis=1)\n",
        "test_labels = np.concatenate([y for x, y in test_data], axis=0)\n",
        "\n",
        "# # Calculate accuracy\n",
        "# accuracy = np.mean(np.equal(predictions, test_labels))\n",
        "# print(\"Accuracy without differential privacy: {:.2f}%\".format(accuracy * 100))\n",
        "# test_labels = np.concatenate([y for x, y in test_data], axis=0)\n",
        "precision = precision_score(test_labels, predictions, average='weighted')\n",
        "recall = recall_score(test_labels, predictions, average='weighted')\n",
        "f1 = f1_score(test_labels, predictions, average='weighted')\n",
        "print(\"Precision without differential privacy: {:.2f}%\".format(precision * 100))\n",
        "print(\"Recall without differential privacy: {:.2f}%\".format(recall * 100))\n",
        "print(\"F1 without differential privacy: {:.2f}%\".format(f1 * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8NZGmGAx0U_o"
      },
      "outputs": [],
      "source": [
        "from tensorflow_privacy.privacy.dp_query.gaussian_query import GaussianSumQuery\n",
        "from tensorflow_privacy.privacy.dp_query.normalized_query import NormalizedQuery\n",
        "from tensorflow_privacy.privacy.dp_query.no_privacy_query import NoPrivacyAverageQuery\n",
        "\n",
        "# Set the privacy parameters\n",
        "epsilon = 1.0\n",
        "delta = 1e-6\n",
        "\n",
        "# Define the differential privacy mechanism with Gaussian noise\n",
        "gaussian_query = GaussianSumQuery(epsilon, delta)\n",
        "normalized_query = NormalizedQuery(gaussian_query, denominator=1.0)\n",
        "noisy_avg = NoPrivacyAverageQuery()\n",
        "# print(gaussian_query.shape,\"gaussian query\")\n",
        "# Clone the model and add differential privacy to the weights\n",
        "model_gau = keras.models.clone_model(model)\n",
        "# for layer in base_model_gau.layers:\n",
        "#     layer.trainable = False\n",
        "model_gau.set_weights(model.get_weights())\n",
        "# global_state = gaussian_query.initial_global_state( )\n",
        "global_state = normalized_query.initial_global_state()\n",
        "\n",
        "\n",
        "for layer in model_gau.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "        # layer.kernel = normalized_query(layer.kernel)\n",
        "        # layer.kernel = normalized_query.get_noised_result(layer.kernel, global_state)\n",
        "        # layer.kernel = tf.reshape(normalized_query.get_noised_result(tf.reshape(layer.kernel, (-1, layer.kernel.shape[-1])), global_state), layer.kernel.shape)\n",
        "        # layer.kernel = tf.reshape(layer.kernel, (-1, layer.kernel.shape[-1]))\n",
        "        # layer.kernel = normalized_query.get_noised_result(layer.kernel, global_state)\n",
        "        # layer.kernel = tf.reshape(layer.kernel, layer.kernel.shape.as_list()[:-1] + [-1])\n",
        "        # layer.kernel = normalized_query.get_noised_result(tf.reshape(layer.kernel, (-1, layer.kernel.shape[-1])), global_state)\n",
        "        kernel, _ ,_= normalized_query.get_noised_result(tf.reshape(layer.kernel, (-1, layer.kernel.shape[-1])), global_state)\n",
        "\n",
        "        layer.kernel = tf.reshape(kernel, layer.kernel.shape)\n",
        "\n",
        "        # layer.kernel = tf.reshape(layer.kernel, list(layer.kernel.shape))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Compile the model with a loss and metrics\n",
        "model_gau.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with the differentially private weights\n",
        "history = model_gau.fit(train_ds, validation_data=val_ds, epochs=1)\n",
        "\n",
        "# Evaluate the model's accuracy with differential privacy\n",
        "test_data = val_ds.take(1)\n",
        "test_images, test_labels = next(iter(test_data))\n",
        "output = model_gau(test_images)\n",
        "# output = model(test_images)\n",
        "predictions_g = tf.argmax(output, axis=1)\n",
        "test_labels = np.concatenate([y for x, y in test_data], axis=0)\n",
        "\n",
        "# Calculate accuracy\n",
        "# accuracy = np.mean(np.equal(predictions, test_labels))\n",
        "# print(\"Accuracy with differential privacy (Gaussian noise): {:.2f}%\".format(accuracy * 100))\n",
        "precision_g = precision_score(test_labels, predictions_g, average='weighted')\n",
        "recall_g = recall_score(test_labels, predictions_g, average='weighted')\n",
        "f1_g = f1_score(test_labels, predictions_g, average='weighted')\n",
        "print(\"Precision with differential privacy (Gaussian noise): {:.2f}%\".format(precision_g * 100))\n",
        "print(\"Recall with differential privacy (Gaussian noise): {:.2f}%\".format(recall_g * 100))\n",
        "print(\"F1 score with differential privacy (Gaussian noise): {:.2f}%\".format(f1_g * 100))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wj47qioPBYIQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Set the privacy parameters\n",
        "epsilon = 0.25\n",
        "delta = 1e-6\n",
        "\n",
        "# Define the differential privacy mechanism with Laplacian noise\n",
        "def add_noise(weights, epsilon):\n",
        "    # print(\"weight shape\", weights.shape)\n",
        "    noise = np.random.laplace(scale=2.0 / epsilon, size=weights.shape)\n",
        "    return weights + noise\n",
        "\n",
        "# Clone the model and add differential privacy to the weights\n",
        "model_lap = keras.models.clone_model(model)\n",
        "model_lap.set_weights(model.get_weights())\n",
        "for layer in model_lap.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "        layer.kernel = add_noise(layer.kernel, epsilon)\n",
        "\n",
        "# Compile the model with a loss and metrics\n",
        "model_lap.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with the differentially private weights\n",
        "history = model_lap.fit(train_ds, validation_data=val_ds, epochs=1)\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the model's accuracy with differential privacy\n",
        "# Evaluate the model's accuracy with differential privacy\n",
        "test_data = val_ds.take(1)\n",
        "output = model_lap.predict(test_data) # use predict() instead of model_dp()\n",
        "predictions_l = tf.argmax(output, axis=1)\n",
        "test_labels = np.concatenate([y for x, y in test_data], axis=0)\n",
        "# accuracy = tf.reduce_mean(tf.cast(predictions == test_labels, tf.float32))\n",
        "# print(\"Accuracy with differential privacy (Laplacian noise): {:.2f}%\".format((accuracy * 100)))\n",
        "precision_l = precision_score(test_labels, predictions_l, average='weighted')\n",
        "recall_l = recall_score(test_labels, predictions_l, average='weighted')\n",
        "f1_l = f1_score(test_labels, predictions_l, average='weighted')\n",
        "print(\"Precision with differential privacy (Laplacian noise): {:.2f}%\".format(precision_l * 100))\n",
        "print(\"Recall with differential privacy (Laplacian noise): {:.2f}%\".format(recall_l * 100))\n",
        "print(\"F1 score with differential privacy (Laplacian noise): {:.2f}%\".format(f1_l * 100))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4wOoTBVu4SA"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "# from tensorflow_privacy.privacy.dp_query.gaussian_query import GaussianSumQuery\n",
        "\n",
        "# Set the privacy parameters\n",
        "epsilon = 0.25\n",
        "delta = 1e-6\n",
        "laplacian_scale = 2.0 / epsilon\n",
        "\n",
        "# Define the differential privacy mechanism with composite noise\n",
        "gaussian_query = GaussianSumQuery(epsilon, delta)\n",
        "normalized_query = NormalizedQuery(gaussian_query, denominator=1.0)\n",
        "noisy_avg = NoPrivacyAverageQuery()\n",
        "global_state = normalized_query.initial_global_state()\n",
        "\n",
        "# Clone the model and add differential privacy to the weights\n",
        "model_com = keras.models.clone_model(model)\n",
        "model_com.set_weights(model.get_weights())\n",
        "\n",
        "for layer in model_com.layers:\n",
        "    if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Dense):\n",
        "        # Add composite noise to the weights\n",
        "        noise, _, _ = normalized_query.get_noised_result(tf.reshape(layer.kernel, (-1, layer.kernel.shape[-1])), global_state)\n",
        "        noise = tf.reshape(noise, layer.kernel.shape)\n",
        "        laplacian_noise = np.random.laplace(scale=laplacian_scale, size=layer.kernel.shape)\n",
        "        layer.kernel = layer.kernel + noise + laplacian_noise\n",
        "\n",
        "# Compile the model with a loss and metrics\n",
        "model_com.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with the differentially private weights\n",
        "history = model_com.fit(train_ds, validation_data=val_ds, epochs=1)\n",
        "\n",
        "# Evaluate the model's accuracy with differential privacy\n",
        "test_data = val_ds.take(1)\n",
        "output = model_com.predict(test_data) # use predict() instead of model_dp()\n",
        "predictions_c = tf.argmax(output, axis=1)\n",
        "test_labels = np.concatenate([y for x, y in test_data], axis=0)\n",
        "accuracy = tf.reduce_mean(tf.cast(predictions_c == test_labels, tf.float32))\n",
        "print(\"Accuracy with differential privacy (Composite noise): {:.2f}%\".format(accuracy * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TCDoeiayiLH0",
        "outputId": "8e17ba72-69d0-43f3-d49a-f813fd2f6d37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 21s 547ms/step\n",
            "1/1 [==============================] - 0s 452ms/step\n",
            "Epoch 1/2\n",
            "36/36 [==============================] - 1s 3ms/step - loss: 0.6055 - accuracy: 0.7835\n",
            "Epoch 2/2\n",
            "36/36 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.9722\n",
            "35/35 [==============================] - 0s 1ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Membership inference attack accuracy on train data:  0.9721739130434782\n",
            "Membership inference attack accuracy on test data:  0.0\n"
          ]
        }
      ],
      "source": [
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# # Generate synthetic data\n",
        "\n",
        "# num_features = 10\n",
        "# x_train = np.random.rand(num_samples, num_features)\n",
        "# y_train = np.random.randint(2, size=num_samples)\n",
        "\n",
        "# # Train a machine learning model\n",
        "# model = keras.Sequential([\n",
        "#     layers.Dense(64, activation='relu', input_shape=(num_features,)),\n",
        "#     layers.Dense(64, activation='relu'),\n",
        "#     layers.Dense(1, activation='sigmoid')\n",
        "# ])\n",
        "# model.compile(optimizer='adam',\n",
        "#               loss='binary_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "# model.fit(x_train, y_train, epochs=10)\n",
        "\n",
        "# # Split the data into train and test sets\n",
        "# x_test = np.random.rand(num_samples, num_features)\n",
        "# y_test = np.random.randint(2, size=num_samples)\n",
        "\n",
        "# Perform a membership inference attack\n",
        "train_preds = model.predict(train_images)\n",
        "test_preds = model.predict(test_images)\n",
        "train_labels = np.ones_like(train_labels)\n",
        "test_labels = np.zeros_like(test_labels)\n",
        "train_data = np.concatenate((train_preds, train_labels.reshape(-1, 1)), axis=1)\n",
        "test_data = np.concatenate((test_preds, test_labels.reshape(-1, 1)), axis=1)\n",
        "num_samples=len(train_data)+len(test_data)\n",
        "# Train a binary classifier to distinguish between train and test data\n",
        "attack_model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(3,)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "num_samples = len(train_data) + len(test_data)\n",
        "attack_targets = np.concatenate((np.ones(len(train_data)), np.zeros(len(test_data))))\n",
        "# attack_targets = np.concatenate((attack_targets, np.zeros(len(train_data))))\n",
        "# attack_targets = np.concatenate((attack_targets, np.ones(len(test_data))))\n",
        "\n",
        "attack_model.compile(optimizer='adam',\n",
        "                     loss='binary_crossentropy',\n",
        "                     metrics=['accuracy'])\n",
        "\n",
        "attack_model.fit(np.concatenate((train_data, test_data)), attack_targets, epochs=2, batch_size=32)\n",
        "\n",
        "# attack_model.fit(np.concatenate((train_data, test_data)), np.concatenate((np.ones(num_samples), np.zeros(num_samples))),\n",
        "#                  epochs=1, batch_size=32)\n",
        "\n",
        "# Evaluate the attack model\n",
        "train_attack_preds = attack_model.predict(train_data)\n",
        "test_attack_preds = attack_model.predict(test_data)\n",
        "train_attack_acc = np.sum(train_attack_preds > 0.5) / num_samples\n",
        "test_attack_acc = np.sum(test_attack_preds <= 0.5) / num_samples\n",
        "\n",
        "print(\"Membership inference attack accuracy on train data: \", train_attack_acc)\n",
        "print(\"Membership inference attack accuracy on test data: \", test_attack_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwoQNj2RV0NF"
      },
      "source": [
        "#Commented Code"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}